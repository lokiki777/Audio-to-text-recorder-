<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Raw Audio to Text Transcriber (Manual Stop)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    fontFamily: {
                        sans: ['Inter', 'sans-serif'],
                    },
                }
            }
        }
    </script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');
        .status-message {
            transition: all 0.3s ease;
        }
        /* Custom pulsing effect for recording */
        .record-active {
            animation: pulse-red 1s infinite;
        }
        @keyframes pulse-red {
            0%, 100% { box-shadow: 0 0 0 0 rgba(220, 38, 38, 0.7); }
            50% { box-shadow: 0 0 0 10px rgba(220, 38, 38, 0); }
        }
    </style>
</head>
<body class="bg-gray-50 min-h-screen flex items-center justify-center p-4 font-sans">

    <div id="app-container" class="w-full max-w-xl bg-white p-8 rounded-xl shadow-2xl border border-gray-100">
        <h1 class="text-3xl font-bold text-gray-800 text-center mb-6">Raw Audio to Text Transcriber</h1>
        <p class="text-center text-gray-500 mb-8">
            This tool provides **full manual control** over the duration. It uses the browser's native speech recognition, providing raw, non-AI-modified transcription only when you click 'Stop Listening.'
            <span class="font-semibold text-red-500 block mt-2">Note: Best supported in Google Chrome and Microsoft Edge.</span>
        </p>

        <!-- Status Message Area -->
        <div id="status-container" class="h-8 mb-6 flex items-center justify-center">
            <p id="status-text" class="status-message text-sm text-gray-500 font-medium">Initializing...</p>
        </div>

        <!-- Recording Controls -->
        <div class="flex flex-col sm:flex-row justify-center space-y-4 sm:space-y-0 sm:space-x-4 mb-8">
            <button id="record-button" 
                    class="flex items-center justify-center px-6 py-3 text-lg font-semibold text-white bg-green-600 hover:bg-green-700 rounded-lg shadow-md transition duration-300 transform hover:scale-[1.02] disabled:opacity-50 disabled:cursor-not-allowed">
                <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 mr-2" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
                    <path stroke-linecap="round" stroke-linejoin="round" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m8 0h-2M12 11V7h1a3 3 0 00-3-3v0a3 3 0 00-3 3v4m3 0a3 3 0 00-3 3v0a3 3 0 003 3v0"/>
                </svg>
                <span id="record-button-text">Start Listening</span>
            </button>
            
            <button id="stop-button" 
                    class="flex items-center justify-center px-6 py-3 text-lg font-semibold text-gray-700 bg-red-400 hover:bg-red-500 rounded-lg shadow-md transition duration-300 transform hover:scale-[1.02] disabled:opacity-50 disabled:cursor-not-allowed" 
                    disabled>
                <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 mr-2" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
                    <path stroke-linecap="round" stroke-linejoin="round" d="M21 12a9 9 0 11-18 0 9 9 0 0118 0z" />
                    <path stroke-linecap="round" stroke-linejoin="round" d="M9 10h6a1 1 0 011 1v2a1 1 0 01-1 1H9a1 1 0 01-1-1v-2a1 1 0 011-1z" />
                </svg>
                Stop Listening
            </button>
        </div>

        <!-- Transcription Result Area -->
        <div class="bg-gray-50 p-4 rounded-lg border border-gray-200">
            <h2 class="text-xl font-semibold text-gray-700 mb-3 flex justify-between items-center">
                Transcription Result
                <button id="copy-button" 
                        class="px-3 py-1 text-sm font-medium text-blue-600 bg-transparent border border-blue-600 rounded-md hover:bg-blue-50 transition duration-150 disabled:opacity-50 disabled:cursor-not-allowed" 
                        disabled>
                    Copy Text
                </button>
            </h2>
            <textarea id="transcription-text" 
                      readonly 
                      rows="10" 
                      placeholder="Click 'Start Listening,' speak for as long as you need, then click 'Stop Listening' to finalize the text." 
                      class="w-full p-3 text-gray-800 bg-white border border-gray-300 rounded-md focus:outline-none focus:ring-2 focus:ring-blue-500 resize-none text-base"></textarea>
        </div>
        
    </div>

    <script>
        // Check for browser compatibility (using vendor prefixes for broader support)
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        
        // --- DOM Elements ---
        const recordButton = document.getElementById('record-button');
        const stopButton = document.getElementById('stop-button');
        const transcriptionTextarea = document.getElementById('transcription-text');
        const copyButton = document.getElementById('copy-button');
        const statusText = document.getElementById('status-text');

        let recognition;
        let isListening = false;
        let accumulatedText = '';

        /**
         * Updates the status message in the UI.
         */
        const updateStatus = (message, type = 'info') => {
            statusText.textContent = message;
            statusText.className = 'status-message text-sm font-medium';
            
            switch (type) {
                case 'listening':
                    statusText.classList.add('text-red-600', 'font-bold');
                    break;
                case 'success':
                    statusText.classList.add('text-green-600');
                    break;
                case 'error':
                    statusText.classList.add('text-red-600');
                    console.error('ERROR:', message);
                    break;
                default:
                    statusText.classList.add('text-gray-500');
            }
        };

        /**
         * Initializes and starts the Web Speech API recognition.
         */
        function startListening() {
            if (!SpeechRecognition) {
                updateStatus('Speech Recognition not supported in this browser. Please use Chrome or Edge.', 'error');
                recordButton.disabled = true;
                return;
            }

            if (isListening) return;
            
            // Clear previous content
            transcriptionTextarea.value = '';
            accumulatedText = '';
            copyButton.disabled = true;

            recognition = new SpeechRecognition();
            // Crucial setting: continuous: true means it will NOT stop until you manually click stop.
            recognition.interimResults = true; 
            recognition.continuous = true;   
            recognition.lang = 'en-US'; 

            // --- Event Handlers ---

            recognition.onstart = () => {
                isListening = true;
                recordButton.disabled = true;
                stopButton.disabled = false;
                recordButton.classList.add('record-active');
                updateStatus('LISTENING... Click "Stop Listening" when finished to process the final text.', 'listening');
            };

            recognition.onresult = (event) => {
                let currentTranscript = '';
                // Loop through all results since the start of the recognition
                for (let i = event.resultIndex; i < event.results.length; ++i) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        // If it's a final result, add it to our accumulated text
                        accumulatedText += transcript + ' ';
                    } else {
                        // If it's an interim result, keep it separate for real-time display
                        currentTranscript += transcript;
                    }
                }
                
                // Display the combination of all final results plus the current interim text
                transcriptionTextarea.value = accumulatedText + currentTranscript;
            };

            recognition.onerror = (event) => {
                isListening = false;
                stopListeningVisuals();
                const errorMessage = `Recognition Error: ${event.error}. Please ensure microphone access is granted.`;
                updateStatus(errorMessage, 'error');
                console.error(errorMessage);
            };

            recognition.onend = () => {
                // This event fires when we manually call recognition.stop()
                isListening = false;
                stopListeningVisuals();
                
                // Final update of the text area with just the accumulated final text
                const finalTranscript = accumulatedText.trim();
                transcriptionTextarea.value = finalTranscript;
                
                if (finalTranscript) {
                    updateStatus('Transcription finalized and ready to copy.', 'success');
                    copyButton.disabled = false;
                } else {
                     updateStatus('Stopped. No speech was detected or finalized.', 'info');
                }
            };
            
            // Start the recognition
            recognition.start();
        }

        /**
         * Stops the recognition manually, triggering the onend event.
         */
        function stopListening() {
            if (recognition) {
                recognition.stop();
            }
        }
        
        /**
         * Resets UI elements after listening stops.
         */
        function stopListeningVisuals() {
            recordButton.disabled = false;
            stopButton.disabled = true;
            recordButton.classList.remove('record-active');
        }

        /**
         * Copies the transcribed text to the clipboard.
         */
        function copyText() {
            const textToCopy = transcriptionTextarea.value;
            if (textToCopy) {
                // Use execCommand for broader compatibility in iFrames
                transcriptionTextarea.select();
                document.execCommand('copy');
                updateStatus("Text copied to clipboard!", 'success');
                setTimeout(() => {
                    // Revert status message if it hasn't changed
                    if (statusText.textContent === "Text copied to clipboard!") {
                         updateStatus("Transcription finalized and ready to copy.", 'success');
                    }
                }, 2000);
            }
        }

        // --- Event Listeners and Initialization ---
        recordButton.addEventListener('click', startListening);
        stopButton.addEventListener('click', stopListening);
        copyButton.addEventListener('click', copyText);

        window.onload = () => {
            if (SpeechRecognition) {
                updateStatus("System Ready. Click 'Start Listening' to begin manual transcription.");
            } else {
                updateStatus('Speech Recognition not supported in this browser. Please use Chrome or Edge.', 'error');
                recordButton.disabled = true;
            }
        };
    </script>
</body>
</html>
